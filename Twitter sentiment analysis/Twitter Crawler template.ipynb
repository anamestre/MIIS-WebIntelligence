{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install the twitter library in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (3.8.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from tweepy) (1.7.1)\n",
      "Requirement already satisfied: requests>=2.11.1 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2019.9.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install library for JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simplejson in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (3.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install simplejson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install sentiment analysis library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in /Users/albertlleo/opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# Whatever library you use\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming tweets and perform some data analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up and running a streaming crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting code\n",
      "<tweepy.auth.OAuthHandler object at 0x10ab27f50>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'twitter_stream = Stream(auth, MyListener(\\'gobierno2.json\\'))\\ntwitter_stream.filter(track=[\"gobierno\", \"elecciones\"], languages=[\"es\"]) # Add your keywords and other filters\\n\\ntwitter_stream = Stream(auth, MyListener(\\'pp.json\\'))\\ntwitter_stream.filter(track=[\"pp\"], languages=[\"es\"]) # Add your keywords and other filters\\n\\ntwitter_stream = Stream(auth, MyListener(\\'psoe.json\\'))\\ntwitter_stream.filter(track=[\"psoe\"], languages=[\"es\"]) # Add your keywords and other filters\\n\\ntwitter_stream = Stream(auth, MyListener(\\'cat.json\\'))\\ntwitter_stream.filter(track=[\"cataluña\", \"catalunya\"], languages=[\"es\"]) # Add your keywords and other filters\\n\\ntwitter_stream = Stream(auth, MyListener(\\'vox.json\\'))\\ntwitter_stream.filter(track=[\"vox\"], languages=[\"es\"]) # Add your keywords and other filters\\n\\ntwitter_stream = Stream(auth, MyListener(\\'ciudadanos.json\\'))\\ntwitter_stream.filter(track=[\"ciudadanos\", \"ciutadans\"], languages=[\"es\"]) # Add your keywords and other filters\\n\\ntwitter_stream = Stream(auth, MyListener(\\'podemos.json\\'))\\ntwitter_stream.filter(track=[\"podemos\"], languages=[\"es\"]) # Add your keywords and other filters\\n\\nprint(\\'_______ End _______\\')'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "import simplejson as json\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "from textblob import TextBlob\n",
    " \n",
    "#Complete with your keys \n",
    "\n",
    "consumer_key = 'aCqrloIHCuvw8rX8sON8B551T'\n",
    "consumer_secret = 'CkkLBIClzyC2w00oHOateou4wxJ2IberPKXWR8WpQEi0T5Gh2s'\n",
    "access_token = '173960222-v34xiH0gEFqXCoVvpnh3JgMp8xwVukAX61rqazBc'\n",
    "access_secret = '9ey7wPBUkPJdu2ZxaBoOUr43dmFCj2Fql1MxBCPKEoVFg'\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "print(\"Starting code\")\n",
    "print(auth)\n",
    " \n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    \n",
    "    def __init__(self, filename, api=None):\n",
    "        super(StreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.filename = filename\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            with open(self.filename, 'a') as f:\n",
    "                #print(\"test\")\n",
    "                if json.loads(data).get('place'):\n",
    "                    print(json.loads(data)['place']['country'])\n",
    "                    if json.loads(data)['place']['country'].lower() in ['spain', 'españa', 'espana']:\n",
    "                        f.write(data) # This will store the whole JSON data in the file, you can perform some JSON filters\n",
    "                        twitter_text = json.loads(data)['text'] # You can also print your tweets here\n",
    "                        print(twitter_text)\n",
    "                        self.num_tweets += 1\n",
    "\n",
    "                # Just to limit the number of tweets collected to check the \n",
    "                # program at the beginning, then increase the limit\n",
    "                if self.num_tweets < 100:\n",
    "                    return True\n",
    "                else:\n",
    "                    print('______________ END ', self.filename)\n",
    "                    return False\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print('Error :', status.place)\n",
    "        return False\n",
    "    \n",
    "\"\"\"twitter_stream = Stream(auth, MyListener('gobierno2.json'))\n",
    "twitter_stream.filter(track=[\"gobierno\", \"elecciones\"], languages=[\"es\"]) # Add your keywords and other filters\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener('pp.json'))\n",
    "twitter_stream.filter(track=[\"pp\"], languages=[\"es\"]) # Add your keywords and other filters\n",
    "\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener('psoe.json'))\n",
    "twitter_stream.filter(track=[\"psoe\"], languages=[\"es\"]) # Add your keywords and other filters\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener('cat.json'))\n",
    "twitter_stream.filter(track=[\"cataluña\", \"catalunya\"], languages=[\"es\"]) # Add your keywords and other filters\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener('vox.json'))\n",
    "twitter_stream.filter(track=[\"vox\"], languages=[\"es\"]) # Add your keywords and other filters\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener('ciudadanos.json'))\n",
    "twitter_stream.filter(track=[\"ciudadanos\", \"ciutadans\"], languages=[\"es\"]) # Add your keywords and other filters\n",
    "\"\"\"\n",
    "twitter_stream = Stream(auth, MyListener('podemos.json'))\n",
    "twitter_stream.filter(track=[\"podemos\"], languages=[\"es\"]) # Add your keywords and other filters\n",
    "\n",
    "print('_______ End _______')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the JSON data in a CSV for analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "\n",
    "# Create the CSV file\n",
    "files = [\"gobierno\", \"cat\", \"podemos\", \"pp\", \"vox\", \"ciudadanos\", \"psoe\"]\n",
    "\n",
    "for file in files:\n",
    "    with open (file + \".csv\", 'w', encoding ='utf-8') as csv:\n",
    "        # Write the title of the columns (features) that you want to store in the CSV file\n",
    "        csv.write('id,'+'created_at'+'text,'+'country'+'\\n')\n",
    "\n",
    "        # Copy the data from the JSON file\n",
    "        with open(file + \".json\", 'r', encoding ='utf-8') as jsonfile:\n",
    "            for tweet in jsonfile: \n",
    "                data = json.loads(tweet)\n",
    "\n",
    "                # The int values should be converted to strings\n",
    "                csv.write(str(data['id'])+',')\n",
    "                csv.write(str(data['created_at'])+',') \n",
    "                csv.write((str(data['text']).replace('\\n', \"\").replace(',', \"\"))+',') \n",
    "                #csv.write(str(data['place']['country'])) \n",
    "                csv.write('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the previous CSV into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "created_attext\n",
      "country\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets_all = pd.read_csv('pp.csv', index_col=0, encoding='ISO-8859-1')\n",
    "count=0\n",
    "for tweet in tweets_all:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the polarity of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 1.1363636363636365 %\n",
      "Negative tweets percentage: 1.1363636363636365 %\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2a9ef87dfb69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-2a9ef87dfb69>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative tweets percentage: {} %\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# percentage of neutral tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neutral tweets percentage: {} % \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntweets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# printing first 5 positive tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import re \n",
    "\n",
    "\n",
    "\n",
    "def clean_tweet(tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "  \n",
    "def get_tweet_sentiment(tweet): \n",
    "    ''' \n",
    "    Utility function to classify sentiment of passed tweet \n",
    "    using textblob's sentiment method \n",
    "    '''\n",
    "    # create TextBlob object of passed tweet text \n",
    "    analysis = TextBlob(clean_tweet(tweet)) \n",
    "    # set sentiment \n",
    "    if analysis.sentiment.polarity > 0: \n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0: \n",
    "        return 'neutral'\n",
    "    else: \n",
    "        return 'negative'                               \n",
    "\n",
    "def featched_tweets(tweets):\n",
    "    try:\n",
    "        tweets_clean=[]\n",
    "        for tweet in tweets:\n",
    "            # empty dictionary to store required params of a tweet \n",
    "            parsed_tweet = {} \n",
    "\n",
    "            # saving text of tweet \n",
    "            parsed_tweet['text'] = tweet \n",
    "            # saving sentiment of tweet \n",
    "            parsed_tweet['sentiment'] = get_tweet_sentiment(tweet) \n",
    "\n",
    "            # appending parsed tweet to tweets list \n",
    "           \n",
    "            tweets_clean.append(parsed_tweet) \n",
    "\n",
    "        # return parsed tweets \n",
    "        return tweets_clean\n",
    "        \n",
    "    except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e))\n",
    "                               \n",
    "def main(): \n",
    "     \n",
    "    tweets = featched_tweets(tweets_all[\"created_attext\"])\n",
    "    # picking positive tweets from tweets found before\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    # percentage of neutral tweets \n",
    "    print(\"Neutral tweets percentage: {} % \".format(100*len(set(tweets) - set(ntweets) - set(ptweets)/len(set(tweets))))) \n",
    "  \n",
    "    # printing first 5 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "    # printing first 5 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    main()                                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = \" \".join(review for review in tweets.text)\n",
    "print(\"There are {} words in the combination of all review. \".format(len(text)))\n",
    "\n",
    "#create stopword list\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"http\",\"https\", \"co\"])\n",
    "\n",
    "# generate wordcloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords,background_color=\"white\").generate(text)\n",
    "\n",
    "#Display generated image:\n",
    "\n",
    "plt.figure(fgisize=(10,15))\n",
    "plt.imshow(worldcloud, interplotation'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your own analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
